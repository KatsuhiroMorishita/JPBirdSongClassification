# for model 20231216

# 学習モデルを動かすための設定
GPU: True       # GPUを使うならTrue
batch_size: 100  # 1度に予測する画像枚数。GPU使用で100とかだと若干だが時短になる

# 識別対象の設定（*を使ってパターンにマッチするファイルを全て処理できます。）
file_names: glob.glob(r'./data/sounds/*.wav')


# その他の設定
mode: "sound"   # image or sound
size: [200, 120, 3]  # 識別機用の画像のサイズ. (width, height, channel)
models: "./models/moel20231216/modelSavedModel"   # モデルの選択
model_format: "SavedModel"   # 保存するモデルの形式. "SavedModel" or ".hdf5"
th: 0.5          # 尤度で識別した、と判断する閾値
loss: "local.focal_loss"    # 損失関数


# 音源からスペクトログラムを作るための設定（学習に使用した画像の生成条件と揃えること）
imagegen_params:    # スペクトログラムを作る基本関数へ渡すパラメータ
  sr: 44100         # 読み込み後のサンプリングレート。音源と異なる場合はリサンプリングされて時間がかかる。
  n_mels: 120       # スペクトログラムを作成する際の周波数のビン数。縦方向のピクセル数に関係する。
  fmax: 22000       # 画像上端の周波数
  n_fft: 2048       # フーリエ変換に使うポイント数
  top_remove: 0     # 内部で画像生成後に削る上端のピクセル数。縦のピクセル数はn_mels-top_removeとなる。
  raw: True         # スペクトログラムに生の音声の振幅情報を埋め込むかどうか。Trueで埋め込む。
  #cut_band: [[15000, 22000, "lower"]]

load_mode: "kaiser_fast"   # 読み込む方法。mp3で影響大。kaiser_bestの方が綺麗ではある。
hop: 0.0251       # 1 pixel幅に相当する時間幅[秒]
window_size: 5    # 1枚の画像にする時間幅[秒]
shift_rate: 1.0     # 次の画像生成のためにどの程度ずらすかを決める。1だとオーバーラップなしで次のwindow_size秒後から作り始める。1以上でもOK。


# 前処理の設定
preprocess_chain: ["preprocessing", "preprocessing3"]

